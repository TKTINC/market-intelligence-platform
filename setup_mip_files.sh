#!/bin/bash

# ==============================================================================
# MARKET INTELLIGENCE PLATFORM - PROJECT FILES GENERATOR
# Creates all deployment, testing, and automation files
# ==============================================================================

set -e

GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m'

print_header() {
    echo -e "${BLUE}============================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}============================================${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_info() {
    echo -e "${YELLOW}ðŸ“‹ $1${NC}"
}

print_header "MARKET INTELLIGENCE PLATFORM - FILE GENERATOR"
print_info "This script will create all deployment and automation files for MIP"

# Create directory structure
print_info "Creating directory structure..."
mkdir -p scripts
mkdir -p infrastructure/monitoring
mkdir -p .github/workflows
mkdir -p helm/mip-platform
mkdir -p tests/{unit,integration,e2e}
mkdir -p docs/{api,architecture,user-guides}
mkdir -p database/{migrations}

# ==============================================================================
# 1. AUTOMATION SCRIPTS
# ==============================================================================

print_info "Creating automation scripts..."

# Main automation script
cat > scripts/automation_scripts.sh << 'EOF'
#!/bin/bash

# ==============================================================================
# MARKET INTELLIGENCE PLATFORM - ONE-CLICK AUTOMATION
# Complete deployment and testing automation for local and cloud environments
# ==============================================================================

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_DIR="$PROJECT_ROOT/logs"
DEPLOYMENT_LOG="$LOG_DIR/deployment_$TIMESTAMP.log"
TEST_LOG="$LOG_DIR/testing_$TIMESTAMP.log"

# Default values
ENVIRONMENT="local"
DEPLOY_MONITORING="true"
RUN_TESTS="true"
TEST_TYPE="all"
CLEAN_DEPLOY="false"
SKIP_BUILD="false"
PARALLEL_DEPLOY="true"

print_banner() {
    echo -e "${PURPLE}"
    echo "=================================================================="
    echo "    MARKET INTELLIGENCE PLATFORM - AUTOMATION SUITE"
    echo "    One-Click Deployment & Testing for Local and Cloud"
    echo "=================================================================="
    echo -e "${NC}"
}

print_header() {
    echo ""
    echo -e "${CYAN}============================================${NC}"
    echo -e "${CYAN}$1${NC}"
    echo -e "${CYAN}============================================${NC}"
}

print_step() {
    echo -e "${BLUE}ðŸ“‹ $1${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸ $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

usage() {
    cat << EOF_USAGE
Usage: $0 [OPTIONS]

One-click deployment and testing automation for Market Intelligence Platform

OPTIONS:
    -e, --environment ENV    Environment: local|aws (default: local)
    -t, --test-type TYPE     Test type: all|sanity|integration|e2e|performance|security (default: all)
    -c, --clean             Clean deployment (remove existing containers/resources)
    -s, --skip-build        Skip building container images
    -m, --skip-monitoring   Skip monitoring stack deployment
    -n, --no-tests          Skip running tests
    -p, --no-parallel       Disable parallel deployment
    -v, --verbose           Verbose output
    -h, --help              Show this help message

EXAMPLES:
    # Local deployment with all tests
    $0 --environment local

    # AWS deployment with only sanity tests
    $0 --environment aws --test-type sanity

    # Clean local deployment without tests
    $0 --environment local --clean --no-tests

EOF_USAGE
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -e|--environment)
            ENVIRONMENT="$2"
            shift 2
            ;;
        -t|--test-type)
            TEST_TYPE="$2"
            shift 2
            ;;
        -c|--clean)
            CLEAN_DEPLOY="true"
            shift
            ;;
        -s|--skip-build)
            SKIP_BUILD="true"
            shift
            ;;
        -m|--skip-monitoring)
            DEPLOY_MONITORING="false"
            shift
            ;;
        -n|--no-tests)
            RUN_TESTS="false"
            shift
            ;;
        -p|--no-parallel)
            PARALLEL_DEPLOY="false"
            shift
            ;;
        -v|--verbose)
            set -x
            shift
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            print_error "Unknown option: $1"
            usage
            exit 1
            ;;
    esac
done

# Create log directory
mkdir -p "$LOG_DIR"

print_banner

check_prerequisites() {
    print_header "CHECKING PREREQUISITES"
    
    local missing_tools=()
    
    command -v docker >/dev/null 2>&1 || missing_tools+=("docker")
    command -v docker-compose >/dev/null 2>&1 || missing_tools+=("docker-compose")
    command -v python3 >/dev/null 2>&1 || missing_tools+=("python3")
    
    if [[ "$ENVIRONMENT" == "aws" ]]; then
        command -v aws >/dev/null 2>&1 || missing_tools+=("aws-cli")
        command -v kubectl >/dev/null 2>&1 || missing_tools+=("kubectl")
        command -v helm >/dev/null 2>&1 || missing_tools+=("helm")
    fi
    
    if [[ ${#missing_tools[@]} -gt 0 ]]; then
        print_error "Missing required tools: ${missing_tools[*]}"
        exit 1
    fi
    
    print_success "All prerequisites satisfied"
}

setup_environment() {
    print_header "ENVIRONMENT SETUP"
    print_step "Setting up environment variables..."
    
    if [[ ! -f ".env" ]]; then
        print_step "Creating default .env file..."
        cat > .env << 'EOF_ENV'
# Database Configuration
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=market_intelligence
POSTGRES_USER=mip_user
POSTGRES_PASSWORD=mip_secure_password_2024

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=redis_secure_password_2024

# JWT Secret
JWT_SECRET_KEY=your_jwt_secret_key_change_in_production_2024

# API Keys (REPLACE WITH YOUR ACTUAL KEYS)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key_here

# Service Ports
API_GATEWAY_PORT=8000
AGENT_ORCHESTRATION_PORT=8001
SENTIMENT_ANALYSIS_PORT=8002
GPT4_STRATEGY_PORT=8003
VIRTUAL_TRADING_PORT=8006

# Environment
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO
EOF_ENV
        print_warning "Please update API keys in .env file before proceeding"
    fi
    
    print_success "Environment configured"
}

deploy_local() {
    print_header "DEPLOYING TO LOCAL ENVIRONMENT"
    
    # Start databases first
    print_step "Starting database services..."
    docker-compose up -d postgres redis
    sleep 30
    
    # Start all services
    print_step "Starting all services..."
    docker-compose up -d
    sleep 60
    
    print_success "Local deployment completed"
}

deploy_monitoring() {
    if [[ "$DEPLOY_MONITORING" == "true" ]]; then
        print_step "Deploying monitoring stack..."
        
        if [[ -d "infrastructure/monitoring" ]]; then
            cd infrastructure/monitoring
            docker-compose -f docker-compose.monitoring.yml up -d || print_warning "Monitoring stack not available"
            cd "$PROJECT_ROOT"
        fi
    fi
}

run_tests() {
    if [[ "$RUN_TESTS" == "true" ]]; then
        print_header "RUNNING TESTS"
        
        if [[ -f "scripts/comprehensive_tests.py" ]]; then
            print_step "Installing test dependencies..."
            pip3 install aiohttp asyncio psycopg2-binary redis websockets numpy pandas > /dev/null 2>&1 || true
            
            print_step "Running test suite..."
            python3 scripts/comprehensive_tests.py --env $ENVIRONMENT --test-type $TEST_TYPE || print_warning "Some tests failed"
        else
            print_warning "Test framework not found"
        fi
    fi
}

verify_deployment() {
    print_header "VERIFYING DEPLOYMENT"
    
    print_step "Checking service health..."
    
    local services=(
        "8000:API Gateway"
        "8001:Agent Orchestration"
        "8002:Sentiment Analysis"
        "8006:Virtual Trading"
    )
    
    for service_info in "${services[@]}"; do
        local port=$(echo $service_info | cut -d: -f1)
        local name=$(echo $service_info | cut -d: -f2)
        
        if curl -f -s "http://localhost:$port/health" >/dev/null 2>&1; then
            print_success "$name is healthy"
        else
            print_warning "$name is not responding"
        fi
    done
}

generate_summary() {
    print_header "DEPLOYMENT SUMMARY"
    
    print_success "MIP deployment completed!"
    echo ""
    echo -e "${BLUE}ðŸŒ Service URLs:${NC}"
    echo "   Frontend:        http://localhost:3001"
    echo "   API Gateway:     http://localhost:8000"
    echo "   Grafana:         http://localhost:3000 (admin/admin123)"
    echo ""
    echo -e "${BLUE}ðŸ”§ Management:${NC}"
    echo "   View services:   docker-compose ps"
    echo "   View logs:       docker-compose logs -f [service]"
    echo "   Stop all:        docker-compose down"
    echo ""
    echo -e "${GREEN}ðŸŽ‰ Ready for trading with AI!${NC}"
}

main() {
    cd "$PROJECT_ROOT"
    
    check_prerequisites
    setup_environment
    
    if [[ "$CLEAN_DEPLOY" == "true" ]]; then
        print_step "Cleaning up..."
        docker-compose down -v >/dev/null 2>&1 || true
    fi
    
    if [[ "$ENVIRONMENT" == "local" ]]; then
        deploy_local
        deploy_monitoring
    else
        print_step "Running AWS deployment..."
        bash scripts/aws_deployment_guide.sh || print_error "AWS deployment failed"
    fi
    
    verify_deployment
    run_tests
    generate_summary
}

main "$@"
EOF

chmod +x scripts/automation_scripts.sh
print_success "Created scripts/automation_scripts.sh"

# Local deployment guide
cat > scripts/local_deployment_guide.sh << 'EOF'
#!/bin/bash

# ==============================================================================
# MARKET INTELLIGENCE PLATFORM - LOCAL DEPLOYMENT GUIDE
# Step-by-step deployment for local development environment
# ==============================================================================

set -e

GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

print_step() {
    echo -e "${BLUE}ðŸ“‹ $1${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸ $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

echo -e "${BLUE}============================================${NC}"
echo -e "${BLUE}MIP LOCAL DEPLOYMENT GUIDE${NC}"
echo -e "${BLUE}============================================${NC}"

# Check prerequisites
print_step "Checking prerequisites..."

if ! command -v docker &> /dev/null; then
    print_error "Docker not found. Please install Docker Desktop."
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    print_error "Docker Compose not found."
    exit 1
fi

print_success "Prerequisites check passed"

# Setup environment
print_step "Setting up environment..."

if [[ ! -f ".env" ]]; then
    cp .env.example .env
    print_warning "Created .env file. Please update with your API keys."
fi

# Start deployment
print_step "Starting database services..."
docker-compose up -d postgres redis

print_step "Waiting for databases..."
sleep 30

# Apply database schema
print_step "Applying database schema..."
if [[ -f "database/schema.sql" ]]; then
    docker exec -i $(docker-compose ps -q postgres) psql -U mip_user -d market_intelligence < database/schema.sql
fi

print_step "Starting all services..."
docker-compose up -d

print_step "Waiting for services to start..."
sleep 60

# Health checks
print_step "Performing health checks..."

services=("8000:API Gateway" "8001:Agent Orchestration" "8002:Sentiment Analysis")

for service in "${services[@]}"; do
    port=$(echo $service | cut -d: -f1)
    name=$(echo $service | cut -d: -f2)
    
    if curl -f -s "http://localhost:$port/health" >/dev/null 2>&1; then
        print_success "$name is healthy"
    else
        print_warning "$name not responding"
    fi
done

print_success "Local deployment completed!"

echo ""
echo -e "${BLUE}Service URLs:${NC}"
echo "  API Gateway:  http://localhost:8000"
echo "  Frontend:     http://localhost:3001" 
echo "  Grafana:      http://localhost:3000 (admin/admin123)"
echo ""
echo -e "${BLUE}Next steps:${NC}"
echo "  1. Update API keys in .env file"
echo "  2. Run tests: python3 scripts/comprehensive_tests.py --env local --test-type sanity"
echo "  3. Open frontend at http://localhost:3001"
EOF

chmod +x scripts/local_deployment_guide.sh
print_success "Created scripts/local_deployment_guide.sh"

# AWS deployment guide
cat > scripts/aws_deployment_guide.sh << 'EOF'
#!/bin/bash

# ==============================================================================
# MARKET INTELLIGENCE PLATFORM - AWS DEPLOYMENT GUIDE
# Complete AWS cloud deployment automation
# ==============================================================================

set -e

GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

print_step() {
    echo -e "${BLUE}ðŸ“‹ $1${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸ $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

# Configuration
AWS_REGION=${AWS_REGION:-"us-east-1"}
CLUSTER_NAME="mip-production-cluster"
NAMESPACE="mip-production"

echo -e "${BLUE}============================================${NC}"
echo -e "${BLUE}MIP AWS DEPLOYMENT GUIDE${NC}"
echo -e "${BLUE}============================================${NC}"

# Check AWS prerequisites
print_step "Checking AWS prerequisites..."

required_tools=("aws" "kubectl" "eksctl" "helm" "docker")
missing_tools=()

for tool in "${required_tools[@]}"; do
    if ! command -v $tool &> /dev/null; then
        missing_tools+=($tool)
    fi
done

if [[ ${#missing_tools[@]} -gt 0 ]]; then
    print_error "Missing tools: ${missing_tools[*]}"
    print_info "Please install missing tools and try again"
    exit 1
fi

# Check AWS credentials
if ! aws sts get-caller-identity &> /dev/null; then
    print_error "AWS credentials not configured"
    print_info "Run 'aws configure' to set up credentials"
    exit 1
fi

AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
print_success "AWS Account: $AWS_ACCOUNT_ID"

# Create ECR repositories
print_step "Creating ECR repositories..."

services=("api-gateway" "agent-orchestration" "sentiment-analysis" "gpt4-strategy" "virtual-trading")

for service in "${services[@]}"; do
    if ! aws ecr describe-repositories --repository-names "mip-$service" --region $AWS_REGION &> /dev/null; then
        aws ecr create-repository --repository-name "mip-$service" --region $AWS_REGION
        print_success "Created ECR repository: mip-$service"
    else
        print_success "ECR repository exists: mip-$service"
    fi
done

# Create EKS cluster
print_step "Creating EKS cluster..."

if ! eksctl get cluster --name $CLUSTER_NAME --region $AWS_REGION &> /dev/null; then
    cat > cluster-config.yaml << EOF_CLUSTER
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: $CLUSTER_NAME
  region: $AWS_REGION
  version: "1.28"

managedNodeGroups:
  - name: worker-nodes
    instanceType: m5.large
    minSize: 2
    maxSize: 6
    desiredCapacity: 3
    volumeSize: 50
EOF_CLUSTER
    
    eksctl create cluster -f cluster-config.yaml
    print_success "EKS cluster created"
else
    print_success "EKS cluster exists"
fi

# Update kubeconfig
aws eks update-kubeconfig --region $AWS_REGION --name $CLUSTER_NAME
print_success "Kubeconfig updated"

# Build and push images
print_step "Building and pushing images..."

aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com

for service in "${services[@]}"; do
    if [[ -d "services/$service" ]]; then
        print_step "Building $service..."
        cd "services/$service"
        docker build -t "mip-$service:latest" .
        docker tag "mip-$service:latest" "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/mip-$service:latest"
        docker push "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/mip-$service:latest"
        cd ../..
        print_success "$service pushed to ECR"
    fi
done

# Deploy to Kubernetes
print_step "Deploying to Kubernetes..."

kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# Create basic deployment for API Gateway
kubectl create deployment api-gateway \
    --image="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/mip-api-gateway:latest" \
    --namespace=$NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

kubectl expose deployment api-gateway \
    --port=8000 --target-port=8000 --type=LoadBalancer \
    --namespace=$NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

print_step "Waiting for deployment..."
kubectl wait --for=condition=available --timeout=300s deployment/api-gateway -n $NAMESPACE

# Get service URL
API_URL=$(kubectl get svc api-gateway -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

print_success "AWS deployment completed!"
echo ""
echo -e "${BLUE}Service URLs:${NC}"
echo "  API Gateway: http://$API_URL"
echo ""
echo -e "${BLUE}Management commands:${NC}"
echo "  kubectl get pods -n $NAMESPACE"
echo "  kubectl logs -f deployment/api-gateway -n $NAMESPACE"

# Save deployment info
cat > aws_deployment_info.txt << EOF_INFO
AWS Deployment Information
========================

Cluster: $CLUSTER_NAME
Region: $AWS_REGION
Namespace: $NAMESPACE
API Gateway: http://$API_URL

Commands:
- Update kubeconfig: aws eks update-kubeconfig --region $AWS_REGION --name $CLUSTER_NAME
- View pods: kubectl get pods -n $NAMESPACE
- View logs: kubectl logs -f deployment/api-gateway -n $NAMESPACE
EOF_INFO

print_success "Deployment info saved to aws_deployment_info.txt"
EOF

chmod +x scripts/aws_deployment_guide.sh
print_success "Created scripts/aws_deployment_guide.sh"

# ==============================================================================
# 2. COMPREHENSIVE TESTING FRAMEWORK
# ==============================================================================

print_info "Creating comprehensive testing framework..."

cat > scripts/comprehensive_tests.py << 'EOF'
#!/usr/bin/env python3

"""
Market Intelligence Platform - Comprehensive Testing Framework
================================================================

This script provides automated testing for the entire MIP platform.

Usage:
    python3 comprehensive_tests.py --env local|aws --test-type all|sanity|integration|e2e|performance|security
"""

import asyncio
import aiohttp
import json
import time
import logging
import argparse
import sys
import subprocess
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class TestResult:
    """Test result structure"""
    test_name: str
    status: str  # PASS, FAIL, SKIP
    duration: float
    message: str
    details: Optional[Dict] = None
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.utcnow()

@dataclass
class TestEnvironment:
    """Test environment configuration"""
    name: str
    api_base_url: str
    services: Dict[str, str]

class ComprehensiveTestSuite:
    """Main test suite for Market Intelligence Platform"""
    
    def __init__(self, environment: str = "local"):
        self.environment = environment
        self.config = self._load_environment_config(environment)
        self.test_results: List[TestResult] = []
        self.session: Optional[aiohttp.ClientSession] = None
        
    def _load_environment_config(self, env: str) -> TestEnvironment:
        """Load environment-specific configuration"""
        
        if env == "local":
            return TestEnvironment(
                name="local",
                api_base_url="http://localhost:8000",
                services={
                    "api-gateway": "http://localhost:8000",
                    "agent-orchestration": "http://localhost:8001",
                    "sentiment-analysis": "http://localhost:8002",
                    "gpt4-strategy": "http://localhost:8003",
                    "virtual-trading": "http://localhost:8006"
                }
            )
        elif env == "aws":
            return TestEnvironment(
                name="aws",
                api_base_url="http://api-gateway-url-from-aws",
                services={}
            )
        else:
            raise ValueError(f"Unknown environment: {env}")
    
    async def setup(self):
        """Setup test environment"""
        logger.info(f"Setting up test environment: {self.config.name}")
        
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)
        
        # Wait for services to be ready
        await self._wait_for_services()
        
    async def teardown(self):
        """Cleanup after tests"""
        if self.session:
            await self.session.close()
        
        await self._generate_test_report()
        
    async def _wait_for_services(self, max_wait: int = 300):
        """Wait for all services to be ready"""
        logger.info("Waiting for services to be ready...")
        
        start_time = time.time()
        while time.time() - start_time < max_wait:
            try:
                async with self.session.get(f"{self.config.api_base_url}/health") as resp:
                    if resp.status == 200:
                        logger.info("Services are ready")
                        return
            except Exception:
                pass
            
            await asyncio.sleep(10)
        
        raise RuntimeError("Services did not become ready in time")
    
    # ==============================================================================
    # SANITY TESTS
    # ==============================================================================
    
    async def run_sanity_tests(self) -> List[TestResult]:
        """Run basic sanity tests"""
        logger.info("Running sanity tests...")
        
        sanity_results = []
        
        # Test all service health endpoints
        for service_name, service_url in self.config.services.items():
            sanity_results.append(await self._test_service_health(service_name, service_url))
        
        # Test database connectivity (if local)
        if self.environment == "local":
            sanity_results.append(await self._test_database_connectivity())
            sanity_results.append(await self._test_redis_connectivity())
        
        return sanity_results
    
    async def _test_service_health(self, service_name: str, service_url: str) -> TestResult:
        """Test individual service health"""
        start_time = time.time()
        
        try:
            async with self.session.get(f"{service_url}/health") as resp:
                duration = time.time() - start_time
                
                if resp.status == 200:
                    return TestResult(
                        test_name=f"{service_name}_health",
                        status="PASS",
                        duration=duration,
                        message=f"{service_name} health check passed"
                    )
                else:
                    return TestResult(
                        test_name=f"{service_name}_health",
                        status="FAIL",
                        duration=duration,
                        message=f"{service_name} returned status {resp.status}"
                    )
                    
        except Exception as e:
            return TestResult(
                test_name=f"{service_name}_health",
                status="FAIL",
                duration=time.time() - start_time,
                message=f"{service_name} health check failed: {str(e)}"
            )
    
    async def _test_database_connectivity(self) -> TestResult:
        """Test database connectivity"""
        start_time = time.time()
        
        try:
            # Try to connect using Docker exec
            result = subprocess.run([
                "docker", "exec", "-i",
                "$(docker-compose ps -q postgres)",
                "psql", "-U", "mip_user", "-d", "market_intelligence", "-c", "SELECT 1;"
            ], capture_output=True, text=True, shell=True)
            
            duration = time.time() - start_time
            
            if result.returncode == 0:
                return TestResult(
                    test_name="database_connectivity",
                    status="PASS",
                    duration=duration,
                    message="Database connectivity successful"
                )
            else:
                return TestResult(
                    test_name="database_connectivity",
                    status="FAIL",
                    duration=duration,
                    message="Database connectivity failed"
                )
                
        except Exception as e:
            return TestResult(
                test_name="database_connectivity",
                status="FAIL",
                duration=time.time() - start_time,
                message=f"Database test failed: {str(e)}"
            )
    
    async def _test_redis_connectivity(self) -> TestResult:
        """Test Redis connectivity"""
        start_time = time.time()
        
        try:
            result = subprocess.run([
                "docker", "exec", "-i",
                "$(docker-compose ps -q redis)",
                "redis-cli", "-a", "redis_secure_password_2024", "ping"
            ], capture_output=True, text=True, shell=True)
            
            duration = time.time() - start_time
            
            if result.returncode == 0 and "PONG" in result.stdout:
                return TestResult(
                    test_name="redis_connectivity",
                    status="PASS",
                    duration=duration,
                    message="Redis connectivity successful"
                )
            else:
                return TestResult(
                    test_name="redis_connectivity",
                    status="FAIL",
                    duration=duration,
                    message="Redis connectivity failed"
                )
                
        except Exception as e:
            return TestResult(
                test_name="redis_connectivity",
                status="FAIL",
                duration=time.time() - start_time,
                message=f"Redis test failed: {str(e)}"
            )
    
    # ==============================================================================
    # INTEGRATION TESTS
    # ==============================================================================
    
    async def run_integration_tests(self) -> List[TestResult]:
        """Run integration tests"""
        logger.info("Running integration tests...")
        
        integration_results = []
        
        # Test API Gateway to service communication
        integration_results.append(await self._test_api_gateway_integration())
        
        # Test agent orchestration
        integration_results.append(await self._test_agent_orchestration())
        
        return integration_results
    
    async def _test_api_gateway_integration(self) -> TestResult:
        """Test API Gateway integration"""
        start_time = time.time()
        
        try:
            # Test API Gateway endpoints
            async with self.session.get(f"{self.config.api_base_url}/api/v1/health") as resp:
                duration = time.time() - start_time
                
                if resp.status == 200:
                    return TestResult(
                        test_name="api_gateway_integration",
                        status="PASS",
                        duration=duration,
                        message="API Gateway integration successful"
                    )
                else:
                    return TestResult(
                        test_name="api_gateway_integration",
                        status="FAIL",
                        duration=duration,
                        message=f"API Gateway returned status {resp.status}"
                    )
                    
        except Exception as e:
            return TestResult(
                test_name="api_gateway_integration",
                status="FAIL",
                duration=time.time() - start_time,
                message=f"API Gateway integration failed: {str(e)}"
            )
    
    async def _test_agent_orchestration(self) -> TestResult:
        """Test agent orchestration"""
        start_time = time.time()
        
        try:
            test_request = {
                "symbol": "AAPL",
                "analysis_type": "sentiment"
            }
            
            async with self.session.post(
                f"{self.config.api_base_url}/api/v1/agents/analyze",
                json=test_request
            ) as resp:
                duration = time.time() - start_time
                
                if resp.status in [200, 202]:  # Accept 202 for async processing
                    return TestResult(
                        test_name="agent_orchestration",
                        status="PASS",
                        duration=duration,
                        message="Agent orchestration working"
                    )
                else:
                    return TestResult(
                        test_name="agent_orchestration",
                        status="FAIL",
                        duration=duration,
                        message=f"Agent orchestration failed with status {resp.status}"
                    )
                    
        except Exception as e:
            return TestResult(
                test_name="agent_orchestration",
                status="FAIL",
                duration=time.time() - start_time,
                message=f"Agent orchestration test failed: {str(e)}"
            )
    
    # ==============================================================================
    # END-TO-END TESTS
    # ==============================================================================
    
    async def run_e2e_tests(self) -> List[TestResult]:
        """Run end-to-end tests"""
        logger.info("Running end-to-end tests...")
        
        e2e_results = []
        
        # Test complete workflow
        e2e_results.append(await self._test_complete_workflow())
        
        return e2e_results
    
    async def _test_complete_workflow(self) -> TestResult:
        """Test complete trading workflow"""
        start_time = time.time()
        
        try:
            # This would test a complete user workflow
            # For now, just test that the API is responsive
            async with self.session.get(f"{self.config.api_base_url}/health") as resp:
                duration = time.time() - start_time
                
                if resp.status == 200:
                    return TestResult(
                        test_name="complete_workflow",
                        status="PASS",
                        duration=duration,
                        message="Complete workflow test passed"
                    )
                else:
                    return TestResult(
                        test_name="complete_workflow",
                        status="FAIL",
                        duration=duration,
                        message="Complete workflow test failed"
                    )
                    
        except Exception as e:
            return TestResult(
                test_name="complete_workflow",
                status="FAIL",
                duration=time.time() - start_time,
                message=f"Complete workflow test failed: {str(e)}"
            )
    
    # ==============================================================================
    # PERFORMANCE TESTS
    # ==============================================================================
    
    async def run_performance_tests(self) -> List[TestResult]:
        """Run performance tests"""
        logger.info("Running performance tests...")
        
        performance_results = []
        
        # Test response times
        performance_results.append(await self._test_response_times())
        
        return performance_results
    
    async def _test_response_times(self) -> TestResult:
        """Test API response times"""
        start_time = time.time()
        
        try:
            response_times = []
            
            # Test multiple requests
            for _ in range(5):
                request_start = time.time()
                async with self.session.get(f"{self.config.api_base_url}/health") as resp:
                    request_time = time.time() - request_start
                    if resp.status == 200:
                        response_times.append(request_time)
            
            duration = time.time() - start_time
            avg_response_time = sum(response_times) / len(response_times) if response_times else 999
            
            if avg_response_time < 2.0:  # 2 second threshold
                return TestResult(
                    test_name="response_times",
                    status="PASS",
                    duration=duration,
                    message=f"Average response time: {avg_response_time:.2f}s",
                    details={"avg_response_time": avg_response_time}
                )
            else:
                return TestResult(
                    test_name="response_times",
                    status="FAIL",
                    duration=duration,
                    message=f"Slow response time: {avg_response_time:.2f}s"
                )
                
        except Exception as e:
            return TestResult(
                test_name="response_times",
                status="FAIL",
                duration=time.time() - start_time,
                message=f"Response time test failed: {str(e)}"
            )
    
    # ==============================================================================
    # SECURITY TESTS
    # ==============================================================================
    
    async def run_security_tests(self) -> List[TestResult]:
        """Run security tests"""
        logger.info("Running security tests...")
        
        security_results = []
        
        # Test authentication
        security_results.append(await self._test_authentication())
        
        return security_results
    
    async def _test_authentication(self) -> TestResult:
        """Test authentication"""
        start_time = time.time()
        
        try:
            # Test access without authentication
            async with self.session.get(f"{self.config.api_base_url}/api/v1/protected") as resp:
                duration = time.time() - start_time
                
                # Should return 401 or 404 (if endpoint doesn't exist yet)
                if resp.status in [401, 404]:
                    return TestResult(
                        test_name="authentication",
                        status="PASS",
                        duration=duration,
                        message="Authentication test passed"
                    )
                else:
                    return TestResult(
                        test_name="authentication",
                        status="FAIL",
                        duration=duration,
                        message=f"Authentication test failed: {resp.status}"
                    )
                    
        except Exception as e:
            return TestResult(
                test_name="authentication",
                status="FAIL",
                duration=time.time() - start_time,
                message=f"Authentication test failed: {str(e)}"
            )
    
    # ==============================================================================
    # REPORT GENERATION
    # ==============================================================================
    
    async def _generate_test_report(self):
        """Generate test report"""
        
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r.status == "PASS"])
        failed_tests = len([r for r in self.test_results if r.status == "FAIL"])
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        # Generate HTML report
        html_report = f"""
<!DOCTYPE html>
<html>
<head>
    <title>MIP Test Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background-color: #f4f4f4; padding: 20px; border-radius: 5px; }}
        .summary {{ margin: 20px 0; }}
        .test-result {{ margin: 10px 0; padding: 10px; border-radius: 5px; }}
        .pass {{ background-color: #d4edda; color: #155724; }}
        .fail {{ background-color: #f8d7da; color: #721c24; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>Market Intelligence Platform - Test Report</h1>
        <p>Environment: {self.config.name}</p>
        <p>Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}</p>
    </div>
    
    <div class="summary">
        <h2>Test Summary</h2>
        <p>Total Tests: {total_tests}</p>
        <p>Passed: {passed_tests}</p>
        <p>Failed: {failed_tests}</p>
        <p>Success Rate: {success_rate:.1f}%</p>
    </div>
    
    <div class="results">
        <h2>Test Results</h2>
"""
        
        for result in self.test_results:
            status_class = result.status.lower()
            html_report += f"""
        <div class="test-result {status_class}">
            <h3>{result.test_name}</h3>
            <p>Status: {result.status}</p>
            <p>Duration: {result.duration:.2f}s</p>
            <p>Message: {result.message}</p>
        </div>
"""
        
        html_report += """
    </div>
</body>
</html>
"""
        
        # Save reports
        timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        with open(f"test_report_{self.config.name}_{timestamp}.html", "w") as f:
            f.write(html_report)
        
        # JSON report
        json_report = {
            "environment": self.config.name,
            "timestamp": datetime.utcnow().isoformat(),
            "summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "failed_tests": failed_tests,
                "success_rate": success_rate
            },
            "results": [asdict(result) for result in self.test_results]
        }
        
        with open(f"test_report_{self.config.name}_{timestamp}.json", "w") as f:
            json.dump(json_report, f, indent=2, default=str)
        
        logger.info(f"Test report generated - Success rate: {success_rate:.1f}% ({passed_tests}/{total_tests})")
    
    # ==============================================================================
    # MAIN TEST EXECUTION
    # ==============================================================================
    
    async def run_all_tests(self, test_types: List[str] = None):
        """Run all specified test types"""
        
        if test_types is None:
            test_types = ["sanity", "integration", "e2e", "performance", "security"]
        
        await self.setup()
        
        try:
            if "sanity" in test_types:
                sanity_results = await self.run_sanity_tests()
                self.test_results.extend(sanity_results)
            
            if "integration" in test_types:
                integration_results = await self.run_integration_tests()
                self.test_results.extend(integration_results)
            
            if "e2e" in test_types:
                e2e_results = await self.run_e2e_tests()
                self.test_results.extend(e2e_results)
            
            if "performance" in test_types:
                performance_results = await self.run_performance_tests()
                self.test_results.extend(performance_results)
            
            if "security" in test_types:
                security_results = await self.run_security_tests()
                self.test_results.extend(security_results)
                
        finally:
            await self.teardown()

async def main():
    """Main entry point"""
    
    parser = argparse.ArgumentParser(description="MIP Test Suite")
    parser.add_argument("--env", choices=["local", "aws"], default="local", help="Environment to test")
    parser.add_argument("--test-type", choices=["all", "sanity", "integration", "e2e", "performance", "security"], 
                       default="all", help="Type of tests to run")
    parser.add_argument("--verbose", action="store_true", help="Verbose output")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Determine test types to run
    if args.test_type == "all":
        test_types = ["sanity", "integration", "e2e", "performance", "security"]
    else:
        test_types = [args.test_type]
    
    # Run tests
    test_suite = ComprehensiveTestSuite(args.env)
    await test_suite.run_all_tests(test_types)
    
    # Print summary
    total_tests = len(test_suite.test_results)
    passed_tests = len([r for r in test_suite.test_results if r.status == "PASS"])
    success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
    
    print(f"\n{'='*60}")
    print(f"TEST SUMMARY")
    print(f"{'='*60}")
    print(f"Environment: {args.env}")
    print(f"Total Tests: {total_tests}")
    print(f"Passed: {passed_tests}")
    print(f"Failed: {total_tests - passed_tests}")
    print(f"Success Rate: {success_rate:.1f}%")
    print(f"{'='*60}")
    
    if success_rate >= 90:
        print("ðŸŽ‰ Test suite completed successfully!")
        sys.exit(0)
    else:
        print("âŒ Test suite completed with failures!")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
EOF

chmod +x scripts/comprehensive_tests.py
print_success "Created scripts/comprehensive_tests.py"

# ==============================================================================
# 3. DOCKER CONFIGURATIONS
# ==============================================================================

print_info "Creating Docker configurations..."

# Main docker-compose.yml
cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  # ==============================================================================
  # DATABASE SERVICES
  # ==============================================================================
  postgres:
    image: postgres:15
    container_name: mip-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-market_intelligence}
      POSTGRES_USER: ${POSTGRES_USER:-mip_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-mip_secure_password_2024}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-mip_user}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mip-network

  redis:
    image: redis:7-alpine
    container_name: mip-redis
    command: redis-server --requirepass ${REDIS_PASSWORD:-redis_secure_password_2024}
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-redis_secure_password_2024}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mip-network

  # ==============================================================================
  # CORE SERVICES
  # ==============================================================================
  api-gateway:
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile
    image: mip-api-gateway:latest
    container_name: mip-api-gateway
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-mip_user}:${POSTGRES_PASSWORD:-mip_secure_password_2024}@postgres:5432/${POSTGRES_DB:-market_intelligence}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis_secure_password_2024}@redis:6379
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-your_jwt_secret_key}
      - ENVIRONMENT=${ENVIRONMENT:-development}
    ports:
      - "${API_GATEWAY_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - mip-network

  agent-orchestration:
    build:
      context: ./services/agent-orchestration
      dockerfile: Dockerfile
    image: mip-agent-orchestration:latest
    container_name: mip-agent-orchestration
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-mip_user}:${POSTGRES_PASSWORD:-mip_secure_password_2024}@postgres:5432/${POSTGRES_DB:-market_intelligence}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis_secure_password_2024}@redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    ports:
      - "${AGENT_ORCHESTRATION_PORT:-8001}:8001"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mip-network

  sentiment-analysis:
    build:
      context: ./services/sentiment-analysis
      dockerfile: Dockerfile
    image: mip-sentiment-analysis:latest
    container_name: mip-sentiment-analysis
    environment:
      - MODEL_NAME=ProsusAI/finbert
    ports:
      - "${SENTIMENT_ANALYSIS_PORT:-8002}:8002"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    networks:
      - mip-network

  gpt4-strategy:
    build:
      context: ./services/gpt4-strategy
      dockerfile: Dockerfile
    image: mip-gpt4-strategy:latest
    container_name: mip-gpt4-strategy
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    ports:
      - "${GPT4_STRATEGY_PORT:-8003}:8003"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mip-network

  virtual-trading:
    build:
      context: ./services/virtual-trading
      dockerfile: Dockerfile
    image: mip-virtual-trading:latest
    container_name: mip-virtual-trading
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-mip_user}:${POSTGRES_PASSWORD:-mip_secure_password_2024}@postgres:5432/${POSTGRES_DB:-market_intelligence}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis_secure_password_2024}@redis:6379
    ports:
      - "${VIRTUAL_TRADING_PORT:-8006}:8006"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8006/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mip-network

volumes:
  postgres_data:
  redis_data:

networks:
  mip-network:
    driver: bridge
EOF

print_success "Created docker-compose.yml"

# Environment example
cat > .env.example << 'EOF'
# ==============================================================================
# MARKET INTELLIGENCE PLATFORM - ENVIRONMENT CONFIGURATION
# ==============================================================================

# Database Configuration
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=market_intelligence
POSTGRES_USER=mip_user
POSTGRES_PASSWORD=mip_secure_password_2024

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=redis_secure_password_2024

# Security Configuration
JWT_SECRET_KEY=your_jwt_secret_key_change_in_production_2024

# AI Service API Keys (REQUIRED)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key_here

# Service Ports
API_GATEWAY_PORT=8000
AGENT_ORCHESTRATION_PORT=8001
SENTIMENT_ANALYSIS_PORT=8002
GPT4_STRATEGY_PORT=8003
VIRTUAL_TRADING_PORT=8006

# Application Configuration
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# Frontend Configuration
REACT_APP_API_BASE_URL=http://localhost:8000
REACT_APP_WS_URL=ws://localhost:8000/ws
EOF

print_success "Created .env.example"

# ==============================================================================
# 4. MONITORING CONFIGURATION
# ==============================================================================

print_info "Creating monitoring configuration..."

# Monitoring docker-compose
cat > infrastructure/monitoring/docker-compose.monitoring.yml << 'EOF'
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: mip-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:10.0.0
    container_name: mip-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin123}
    restart: unless-stopped
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager:v0.25.0
    container_name: mip-alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
    restart: unless-stopped
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:

networks:
  monitoring:
    driver: bridge
  default:
    external:
      name: mip_mip-network
EOF

# Basic Prometheus config
cat > infrastructure/monitoring/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'mip-services'
    static_configs:
      - targets: ['host.docker.internal:8000', 'host.docker.internal:8001', 'host.docker.internal:8002']
EOF

# Basic AlertManager config
cat > infrastructure/monitoring/alertmanager.yml << 'EOF'
global:
  smtp_smarthost: 'localhost:587'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://127.0.0.1:5001/'
EOF

print_success "Created monitoring configuration"

# ==============================================================================
# 5. DATABASE SCHEMA
# ==============================================================================

print_info "Creating database schema..."

cat > database/schema.sql << 'EOF'
-- ==============================================================================
-- MARKET INTELLIGENCE PLATFORM - DATABASE SCHEMA
-- ==============================================================================

-- Enable UUID extension
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Users table
CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    username VARCHAR(255) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(50) DEFAULT 'user',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Virtual portfolios table
CREATE TABLE IF NOT EXISTS virtual_portfolios (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID REFERENCES users(id),
    name VARCHAR(255) NOT NULL,
    initial_balance DECIMAL(15,2) NOT NULL,
    current_balance DECIMAL(15,2) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Virtual trades table
CREATE TABLE IF NOT EXISTS virtual_trades (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    portfolio_id UUID REFERENCES virtual_portfolios(id),
    symbol VARCHAR(10) NOT NULL,
    action VARCHAR(10) NOT NULL, -- BUY, SELL
    quantity INTEGER NOT NULL,
    price DECIMAL(10,2) NOT NULL,
    commission DECIMAL(10,2) DEFAULT 0,
    executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Market data table
CREATE TABLE IF NOT EXISTS market_data (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    symbol VARCHAR(10) NOT NULL,
    price DECIMAL(10,2) NOT NULL,
    volume BIGINT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Agent analysis results
CREATE TABLE IF NOT EXISTS agent_analysis (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    symbol VARCHAR(10) NOT NULL,
    agent_type VARCHAR(50) NOT NULL,
    analysis_result JSONB NOT NULL,
    confidence_score DECIMAL(3,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes
CREATE INDEX IF NOT EXISTS idx_portfolios_user_id ON virtual_portfolios(user_id);
CREATE INDEX IF NOT EXISTS idx_trades_portfolio_id ON virtual_trades(portfolio_id);
CREATE INDEX IF NOT EXISTS idx_market_data_symbol ON market_data(symbol);
CREATE INDEX IF NOT EXISTS idx_market_data_timestamp ON market_data(timestamp);
CREATE INDEX IF NOT EXISTS idx_analysis_symbol ON agent_analysis(symbol);

-- Insert sample data
INSERT INTO users (username, email, password_hash) VALUES 
('test_user', 'test@example.com', '$2b$12$LQv3c1yqBWVHxkd0LHAkCOYz6TtxMQJqhN8/LewPlb.FhY.Q1ZODa')
ON CONFLICT DO NOTHING;
EOF

print_success "Created database/schema.sql"

# ==============================================================================
# 6. CI/CD PIPELINE
# ==============================================================================

print_info "Creating CI/CD pipeline..."

cat > .github/workflows/ci-cd.yml << 'EOF'
name: Market Intelligence Platform CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: us-east-1

jobs:
  test:
    name: Test Services
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: market_intelligence_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install pytest aiohttp asyncio psycopg2-binary redis

    - name: Run tests
      env:
        DATABASE_URL: postgresql://test_user:test_password@localhost:5432/market_intelligence_test
        REDIS_URL: redis://localhost:6379
      run: |
        python3 scripts/comprehensive_tests.py --env local --test-type sanity

  build:
    name: Build and Push Images
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build images
      run: |
        docker-compose build
        echo "Images built successfully"

    - name: Save build info
      run: |
        echo "Build completed at $(date)" > build_info.txt
        echo "Commit: ${{ github.sha }}" >> build_info.txt
EOF

print_success "Created .github/workflows/ci-cd.yml"

# ==============================================================================
# 7. README FILES
# ==============================================================================

print_info "Creating README files..."

cat > README.md << 'EOF'
# ðŸš€ Market Intelligence Platform (MIP)

## ðŸŽ¯ Quick Start

### One-Click Local Deployment

```bash
# 1. Clone and setup
git clone <your-repo>
cd market-intelligence-platform
chmod +x scripts/*.sh

# 2. Configure environment
cp .env.example .env
# Edit .env with your API keys

# 3. Deploy everything
./scripts/automation_scripts.sh --environment local

# 4. Access your platform
# Frontend: http://localhost:3001
# API: http://localhost:8000
# Grafana: http://localhost:3000 (admin/admin123)
```

### Test Your Deployment

```bash
# Quick health check
python3 scripts/comprehensive_tests.py --env local --test-type sanity

# Full test suite
python3 scripts/comprehensive_tests.py --env local --test-type all
```

## ðŸ—ï¸ Architecture

**Multi-Agent AI System:**
- ðŸ§  FinBERT (Sentiment Analysis)
- ðŸ’¡ GPT-4 (Options Strategies)
- ðŸ“ Llama 2-7B (Explanations)
- ðŸ“Š TFT (Price Forecasting)
- âš–ï¸ Risk Validation

**Core Services:**
- ðŸŒ API Gateway (FastAPI + WebSocket)
- ðŸ¤– Agent Orchestration
- ðŸ’° Virtual Trading Engine
- ðŸ“Š Real-time Monitoring
- ðŸ”’ Enterprise Security

## ðŸ“‹ Prerequisites

- Docker Desktop (8GB+ RAM)
- Python 3.11+
- Node.js 18+ (for frontend)
- API Keys: OpenAI, Anthropic, Alpha Vantage

## ðŸ”§ Management Commands

```bash
# View services
docker-compose ps

# View logs
docker-compose logs -f api-gateway

# Restart service
docker-compose restart virtual-trading

# Stop all
docker-compose down

# Run tests
python3 scripts/comprehensive_tests.py --env local --test-type sanity
```

## ðŸŒ Service URLs (Local)

- **Frontend**: http://localhost:3001
- **API Gateway**: http://localhost:8000
- **Grafana**: http://localhost:3000 (admin/admin123)
- **Prometheus**: http://localhost:9090

## ðŸš¨ Troubleshooting

**Services not starting?**
```bash
docker-compose logs [service-name]
docker-compose restart [service-name]
```

**Need to reset everything?**
```bash
docker-compose down -v
./scripts/automation_scripts.sh --environment local --clean
```

## ðŸŽ‰ What's Included

âœ… **Multi-Agent AI Trading System**  
âœ… **Real-time Virtual Trading**  
âœ… **Production Monitoring Stack**  
âœ… **Enterprise Security**  
âœ… **One-Click Deployment**  
âœ… **Comprehensive Testing**  
âœ… **CI/CD Pipeline**  

**Happy Trading with AI! ðŸŽ¯ðŸ“ˆðŸ¤–**
EOF

print_success "Created README.md"

# ==============================================================================
# 8. TESTING REQUIREMENTS
# ==============================================================================

print_info "Creating test requirements..."

cat > requirements-test.txt << 'EOF'
# Testing framework dependencies
aiohttp>=3.8.0
asyncio-mqtt>=0.11.0
psycopg2-binary>=2.9.0
redis>=4.5.0
websockets>=11.0.0
numpy>=1.24.0
pandas>=2.0.0
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0
requests>=2.31.0
EOF

print_success "Created requirements-test.txt"

# ==============================================================================
# 9. FINALIZE
# ==============================================================================

print_header "FINALIZING PROJECT SETUP"

# Make all scripts executable
chmod +x scripts/*.sh

# Create logs directory
mkdir -p logs

# Create a quick start script
cat > quick_start.sh << 'EOF'
#!/bin/bash

echo "ðŸš€ Market Intelligence Platform - Quick Start"
echo "============================================="

# Check if .env exists
if [[ ! -f ".env" ]]; then
    echo "ðŸ“‹ Setting up environment..."
    cp .env.example .env
    echo "âš ï¸  Please edit .env with your API keys before continuing"
    echo "   Required: OPENAI_API_KEY, ALPHA_VANTAGE_API_KEY"
    read -p "Press Enter after updating .env file..."
fi

echo "ðŸš€ Starting deployment..."
./scripts/automation_scripts.sh --environment local --test-type sanity

echo ""
echo "ðŸŽ‰ Deployment completed!"
echo "ðŸ“± Frontend: http://localhost:3001"
echo "ðŸ”Œ API: http://localhost:8000"
echo "ðŸ“Š Grafana: http://localhost:3000 (admin/admin123)"
echo ""
echo "ðŸ§ª Run full tests: python3 scripts/comprehensive_tests.py --env local --test-type all"
EOF

chmod +x quick_start.sh

print_success "Created quick_start.sh"

print_header "PROJECT FILES CREATION COMPLETED!"

echo ""
print_success "âœ… All MIP deployment and automation files created!"
echo ""
echo -e "${BLUE}ðŸ“ Files Created:${NC}"
echo "   scripts/automation_scripts.sh         - One-click deployment"
echo "   scripts/local_deployment_guide.sh     - Step-by-step local setup"
echo "   scripts/aws_deployment_guide.sh       - AWS cloud deployment"
echo "   scripts/comprehensive_tests.py        - Complete testing framework"
echo "   docker-compose.yml                    - Service orchestration"
echo "   .env.example                          - Environment template"
echo "   database/schema.sql                   - Database schema"
echo "   infrastructure/monitoring/            - Monitoring configs"
echo "   .github/workflows/ci-cd.yml          - CI/CD pipeline"
echo "   README.md                             - Project documentation"
echo "   quick_start.sh                        - Ultra-quick deployment"
echo ""
echo -e "${YELLOW}ðŸš€ Ready to Deploy:${NC}"
echo "   1. Copy environment: cp .env.example .env"
echo "   2. Add your API keys to .env"
echo "   3. Run: ./scripts/automation_scripts.sh --environment local"
echo ""
echo -e "${GREEN}ðŸŽ‰ Your Market Intelligence Platform is ready for deployment!${NC}"
EOF

chmod +x setup_mip_files.sh
print_success "Setup script created successfully!"

echo ""
print_header "SETUP COMPLETE"
print_success "Run this script to create all MIP deployment files:"
print_info "./setup_mip_files.sh"
